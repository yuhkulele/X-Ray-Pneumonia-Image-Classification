{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4b1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "\n",
    "import numpy as np\n",
    "import os, tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import image_dataset_from_directory \n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "import time\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from PIL import Image\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2464e9b2",
   "metadata": {},
   "source": [
    "## Image Load In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb3e2785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\n",
      "Yuhkai_notebook_scratch.ipynb\n",
      "data\n",
      "data.zip\n",
      "notebooks_scratch\n",
      "saved_models\n",
      "simple_cnn.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22933c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce2e6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\n",
      "Yuhkai_notebook_scratch.ipynb\n",
      "data\n",
      "data.zip\n",
      "notebooks_scratch\n",
      "saved_models\n",
      "simple_cnn.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d89e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\n",
      "Yuhkai_notebook_scratch.ipynb\n",
      "data\n",
      "data.zip\n",
      "notebooks_scratch\n",
      "saved_models\n",
      "simple_cnn.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a38bcfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the train data\n",
    "\n",
    "#starting from main project directory\n",
    "\n",
    "train_normal_dir = \"./data/chest_xray/train/NORMAL\"\n",
    "train_pneumonia_dir = \"./data/chest_xray/train/PNEUMONIA\"\n",
    "\n",
    "imgs_train_normal = [file for file in os.listdir(train_normal_dir) if file.endswith('.jpeg')]\n",
    "imgs_train_pneumonia = [file for file in os.listdir(train_pneumonia_dir) if file.endswith('.jpeg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aa8d7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normal_dir = \"./data/chest_xray/test/NORMAL\"\n",
    "test_pneumonia_dir = \"./data/chest_xray/test/PNEUMONIA\"\n",
    "\n",
    "imgs_test_normal = [file for file in os.listdir(test_normal_dir) if file.endswith('.jpeg')]\n",
    "imgs_test_pneumonia = [file for file in os.listdir(test_pneumonia_dir) if file.endswith('.jpeg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1cb7560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1341"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_train_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71fe4696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3875"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_train_pneumonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5935606e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IM-0115-0001.jpeg'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_train_normal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7777fb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'person1000_bacteria_2931.jpeg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_train_pneumonia[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af354b5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_test_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a574ee41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_test_pneumonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bc17eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5216, 624)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train = len(imgs_train_normal) + len(imgs_train_pneumonia)\n",
    "num_test = len(imgs_test_normal) + len(imgs_test_pneumonia)\n",
    "num_train, num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ed59797",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1f99e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4173 images belonging to 2 classes.\n",
      "Found 1043 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#rescale images to 64 by 64\n",
    "#create validation set as 20% of train set\n",
    "\n",
    "train_folder = \"./data/chest_xray/train\"\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "        train_folder, \n",
    "        target_size=(64, 64), \n",
    "        color_mode='grayscale', \n",
    "        class_mode='binary',\n",
    "        subset='training',\n",
    "        batch_size= num_train)\n",
    "\n",
    "validation_gen = train_datagen.flow_from_directory(\n",
    "        train_folder, \n",
    "        target_size=(64, 64), \n",
    "        color_mode='grayscale', \n",
    "        class_mode='binary',\n",
    "        subset='validation',\n",
    "        batch_size= num_train)\n",
    "\n",
    "test_folder = \"./data/chest_xray/test\"\n",
    "test_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, \n",
    "        target_size=(64, 64), color_mode='grayscale', \n",
    "        class_mode='binary', \n",
    "        batch_size= num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "279788e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_gen)\n",
    "val_images, val_labels = next(validation_gen)\n",
    "test_images, test_labels = next(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68728ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.05490196],\n",
       "        [0.05490196],\n",
       "        [0.04313726],\n",
       "        ...,\n",
       "        [0.10588236],\n",
       "        [0.10980393],\n",
       "        [0.16470589]],\n",
       "\n",
       "       [[0.03921569],\n",
       "        [0.04313726],\n",
       "        [0.0627451 ],\n",
       "        ...,\n",
       "        [0.09019608],\n",
       "        [0.10588236],\n",
       "        [0.13725491]],\n",
       "\n",
       "       [[0.01960784],\n",
       "        [0.13725491],\n",
       "        [0.15294118],\n",
       "        ...,\n",
       "        [0.09411766],\n",
       "        [0.09803922],\n",
       "        [0.16078432]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.12156864],\n",
       "        [0.11764707],\n",
       "        [0.11764707],\n",
       "        ...,\n",
       "        [0.10588236],\n",
       "        [0.10980393],\n",
       "        [0.10980393]],\n",
       "\n",
       "       [[0.12156864],\n",
       "        [0.12156864],\n",
       "        [0.11764707],\n",
       "        ...,\n",
       "        [0.10980393],\n",
       "        [0.1137255 ],\n",
       "        [0.1137255 ]],\n",
       "\n",
       "       [[0.12156864],\n",
       "        [0.12156864],\n",
       "        [0.1137255 ],\n",
       "        ...,\n",
       "        [0.10980393],\n",
       "        [0.11764707],\n",
       "        [0.1137255 ]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06e5a2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f594e08c70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[0], cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "935ea49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        ],\n",
       "        [0.        ],\n",
       "        [0.0627451 ],\n",
       "        ...,\n",
       "        [0.05882353],\n",
       "        [0.06666667],\n",
       "        [0.07058824]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.0509804 ],\n",
       "        ...,\n",
       "        [0.05882353],\n",
       "        [0.06666667],\n",
       "        [0.07450981]],\n",
       "\n",
       "       [[0.00392157],\n",
       "        [0.        ],\n",
       "        [0.0509804 ],\n",
       "        ...,\n",
       "        [0.0627451 ],\n",
       "        [0.07058824],\n",
       "        [0.07450981]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.02745098],\n",
       "        [0.01568628],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.0627451 ],\n",
       "        [0.06666667],\n",
       "        [0.07843138]],\n",
       "\n",
       "       [[0.02745098],\n",
       "        [0.01568628],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.0627451 ],\n",
       "        [0.07058824],\n",
       "        [0.07450981]],\n",
       "\n",
       "       [[0.02745098],\n",
       "        [0.01960784],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.0627451 ],\n",
       "        [0.07058824],\n",
       "        [0.07450981]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dc80fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4173, 64, 64, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4e7a439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(image height, image width, color channels)\n",
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "094464c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9afb5b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4173,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a54af6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1043, 64, 64, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dab4d362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1043,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc6b5ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4173, 4096)\n",
      "(1043, 4096)\n",
      "(624, 4096)\n"
     ]
    }
   ],
   "source": [
    "#reshaping features for dense layers\n",
    "train_reshape = train_images.reshape(train_images.shape[0], -1)\n",
    "val_reshape = val_images.reshape(val_images.shape[0], -1)\n",
    "test_reshape = test_images.reshape(test_images.shape[0], -1)\n",
    "\n",
    "print(train_reshape.shape)\n",
    "print(val_reshape.shape)\n",
    "print(test_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fe78056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4173,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ad1fe23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1043,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "faa2ce7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92ed5628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4173, 1)\n",
      "(1043, 1)\n",
      "(624, 1)\n"
     ]
    }
   ],
   "source": [
    "#reshaping labels\n",
    "train_y = np.reshape(train_labels, (4173,1))\n",
    "val_y = np.reshape(val_labels, (1043,1))\n",
    "test_y = np.reshape(test_labels, (624,1))\n",
    "\n",
    "print(train_y.shape)\n",
    "print(val_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6717d227",
   "metadata": {},
   "source": [
    "# Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd619877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7430488974113135"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier()\n",
    "dummy_clf.fit(train_images, train_labels)\n",
    "dummy_clf.score(val_images, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3422e966",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1421aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c88c683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.add(layers.Dense(20, activation='relu', input_shape=(4096,)))\n",
    "baseline_model.add(layers.Dense(7, activation='relu'))\n",
    "baseline_model.add(layers.Dense(5, activation='relu'))\n",
    "baseline_model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f19cf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                81940     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 147       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 82,133\n",
      "Trainable params: 82,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ed41732",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.compile(optimizer='sgd', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "001757f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reshape[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9da999c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_reshape[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6067c9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "131/131 [==============================] - 4s 16ms/step - loss: 0.5611 - accuracy: 0.7388 - val_loss: 0.4850 - val_accuracy: 0.7430\n",
      "Epoch 2/50\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.3848 - accuracy: 0.8289 - val_loss: 0.3847 - val_accuracy: 0.8015\n",
      "Epoch 3/50\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2970 - accuracy: 0.8740 - val_loss: 0.5450 - val_accuracy: 0.7411\n",
      "Epoch 4/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2568 - accuracy: 0.8922 - val_loss: 0.2174 - val_accuracy: 0.9070\n",
      "Epoch 5/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2270 - accuracy: 0.9092 - val_loss: 0.4529 - val_accuracy: 0.8082\n",
      "Epoch 6/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1833 - accuracy: 0.9293 - val_loss: 0.3017 - val_accuracy: 0.8744\n",
      "Epoch 7/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1941 - accuracy: 0.9195 - val_loss: 0.1840 - val_accuracy: 0.9252\n",
      "Epoch 8/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1728 - accuracy: 0.9324 - val_loss: 0.2190 - val_accuracy: 0.9070\n",
      "Epoch 9/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1591 - accuracy: 0.9406 - val_loss: 0.4745 - val_accuracy: 0.8044\n",
      "Epoch 10/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1464 - accuracy: 0.9442 - val_loss: 0.1997 - val_accuracy: 0.9175\n",
      "Epoch 11/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1371 - accuracy: 0.9466 - val_loss: 0.5077 - val_accuracy: 0.7967\n",
      "Epoch 12/50\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.1407 - accuracy: 0.9458 - val_loss: 0.5697 - val_accuracy: 0.8150\n",
      "Epoch 13/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1507 - accuracy: 0.9394 - val_loss: 0.2964 - val_accuracy: 0.8792\n",
      "Epoch 14/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1325 - accuracy: 0.9494 - val_loss: 0.2455 - val_accuracy: 0.9070\n",
      "Epoch 15/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1256 - accuracy: 0.9526 - val_loss: 0.1472 - val_accuracy: 0.9434\n",
      "Epoch 16/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1272 - accuracy: 0.9514 - val_loss: 0.1438 - val_accuracy: 0.9444\n",
      "Epoch 17/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1186 - accuracy: 0.9540 - val_loss: 0.1840 - val_accuracy: 0.9262\n",
      "Epoch 18/50\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1360 - accuracy: 0.9461 - val_loss: 0.1430 - val_accuracy: 0.9463\n",
      "Epoch 19/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1186 - accuracy: 0.9545 - val_loss: 0.1734 - val_accuracy: 0.9319\n",
      "Epoch 20/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1216 - accuracy: 0.9545 - val_loss: 0.1553 - val_accuracy: 0.9396\n",
      "Epoch 21/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1071 - accuracy: 0.9593 - val_loss: 0.2306 - val_accuracy: 0.9118\n",
      "Epoch 22/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1102 - accuracy: 0.9557 - val_loss: 0.1406 - val_accuracy: 0.9473\n",
      "Epoch 23/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1206 - accuracy: 0.9561 - val_loss: 0.2257 - val_accuracy: 0.9108\n",
      "Epoch 24/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1111 - accuracy: 0.9569 - val_loss: 0.1391 - val_accuracy: 0.9453\n",
      "Epoch 25/50\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0994 - accuracy: 0.9636 - val_loss: 0.1442 - val_accuracy: 0.9453\n",
      "Epoch 26/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1069 - accuracy: 0.9612 - val_loss: 0.3903 - val_accuracy: 0.8562\n",
      "Epoch 27/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1117 - accuracy: 0.9588 - val_loss: 0.1536 - val_accuracy: 0.9434\n",
      "Epoch 28/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1042 - accuracy: 0.9624 - val_loss: 0.1791 - val_accuracy: 0.9300\n",
      "Epoch 29/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1217 - accuracy: 0.9547 - val_loss: 0.1516 - val_accuracy: 0.9415\n",
      "Epoch 30/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0991 - accuracy: 0.9617 - val_loss: 0.1576 - val_accuracy: 0.9396\n",
      "Epoch 31/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1049 - accuracy: 0.9607 - val_loss: 0.1372 - val_accuracy: 0.9463\n",
      "Epoch 32/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1044 - accuracy: 0.9602 - val_loss: 0.2065 - val_accuracy: 0.9195\n",
      "Epoch 33/50\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1029 - accuracy: 0.9619 - val_loss: 0.5356 - val_accuracy: 0.7996\n",
      "Epoch 34/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1082 - accuracy: 0.9609 - val_loss: 0.3702 - val_accuracy: 0.8686\n",
      "Epoch 35/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0967 - accuracy: 0.9645 - val_loss: 0.1414 - val_accuracy: 0.9453\n",
      "Epoch 36/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0974 - accuracy: 0.9648 - val_loss: 0.1651 - val_accuracy: 0.9367\n",
      "Epoch 37/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1008 - accuracy: 0.9602 - val_loss: 0.5427 - val_accuracy: 0.8063\n",
      "Epoch 38/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1004 - accuracy: 0.9626 - val_loss: 0.1610 - val_accuracy: 0.9396\n",
      "Epoch 39/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0933 - accuracy: 0.9669 - val_loss: 0.1526 - val_accuracy: 0.9406\n",
      "Epoch 40/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0978 - accuracy: 0.9621 - val_loss: 0.4005 - val_accuracy: 0.8571\n",
      "Epoch 41/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0950 - accuracy: 0.9641 - val_loss: 0.3299 - val_accuracy: 0.8840\n",
      "Epoch 42/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0970 - accuracy: 0.9648 - val_loss: 0.3614 - val_accuracy: 0.8734\n",
      "Epoch 43/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0886 - accuracy: 0.9691 - val_loss: 0.1739 - val_accuracy: 0.9348\n",
      "Epoch 44/50\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9633 - val_loss: 0.1686 - val_accuracy: 0.9358\n",
      "Epoch 45/50\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0888 - accuracy: 0.9662 - val_loss: 0.1551 - val_accuracy: 0.9463\n",
      "Epoch 46/50\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0858 - accuracy: 0.9674 - val_loss: 0.1462 - val_accuracy: 0.9434\n",
      "Epoch 47/50\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0879 - accuracy: 0.9676 - val_loss: 0.1490 - val_accuracy: 0.9453\n",
      "Epoch 48/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0973 - accuracy: 0.9631 - val_loss: 0.1476 - val_accuracy: 0.9434\n",
      "Epoch 49/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0803 - accuracy: 0.9703 - val_loss: 0.2091 - val_accuracy: 0.9281\n",
      "Epoch 50/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0834 - accuracy: 0.9696 - val_loss: 0.2825 - val_accuracy: 0.9003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dfe661ffa0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model.fit(train_reshape, \n",
    "                   train_y, \n",
    "                   epochs=50, \n",
    "                   batch_size=32, \n",
    "                   validation_data=(val_reshape, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f9baa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 1s 7ms/step - loss: 0.2145 - accuracy: 0.9183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21445898711681366, 0.9182842373847961]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train = baseline_model.evaluate(train_reshape, train_y)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d260b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2825 - accuracy: 0.9003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2825089991092682, 0.9002876281738281]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_val = baseline_model.evaluate(val_reshape, val_y)\n",
    "results_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bb455a",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks - CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c34d54c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up a simple convolutional model\n",
    "simple_cnn = models.Sequential()\n",
    "\n",
    "simple_cnn.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', \n",
    "          input_shape=(64, 64, 1)))\n",
    "simple_cnn.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "simple_cnn.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "#single dense layer\n",
    "simple_cnn.add(layers.Flatten())\n",
    "simple_cnn.add(layers.Dense(64, activation='relu'))\n",
    "#output layer\n",
    "simple_cnn.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f6449c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 62, 62, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 29, 29, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 53824)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                3444800   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,482,433\n",
      "Trainable params: 3,482,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bf0c7664",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn.compile(optimizer='sgd',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5e288fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 9s 594ms/step - loss: 0.4193 - accuracy: 0.7992 - precision: 0.7888\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 7s 602ms/step - loss: 0.4524 - accuracy: 0.8243 - precision: 0.8270\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 7s 598ms/step - loss: 0.3948 - accuracy: 0.8351 - precision: 0.8324\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 7s 643ms/step - loss: 0.4293 - accuracy: 0.8112 - precision: 0.8284\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 7s 602ms/step - loss: 0.3908 - accuracy: 0.8430 - precision: 0.8557\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 6s 587ms/step - loss: 0.4066 - accuracy: 0.8203 - precision: 0.8422\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 7s 622ms/step - loss: 0.3139 - accuracy: 0.8890 - precision: 0.8861\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 7s 612ms/step - loss: 0.3312 - accuracy: 0.8658 - precision: 0.8812\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 7s 598ms/step - loss: 0.4278 - accuracy: 0.8387 - precision: 0.8539\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 7s 610ms/step - loss: 0.2801 - accuracy: 0.9001 - precision: 0.8999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dfcd45c730>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn.fit(train_images, train_labels, epochs=10, batch_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6e3af26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 4s 22ms/step - loss: 0.2789 - accuracy: 0.9154 - precision: 0.9467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2788931131362915, 0.9154085516929626, 0.9466666579246521]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn_train = simple_cnn.evaluate(train_images, train_labels)\n",
    "simple_cnn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "41a4c57e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 25ms/step - loss: 0.3074 - accuracy: 0.8859 - precision: 0.9216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30743056535720825, 0.8859060406684875, 0.9215938448905945]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn_val = simple_cnn.evaluate(val_images, val_labels)\n",
    "simple_cnn_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee00b1",
   "metadata": {},
   "source": [
    "Our first CNN had some overfitting (91% accuracy on the train set and 89% accuracy on the validation set). Precision was also better for the train set (94%) than the validation set (92%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c0260709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(simple_cnn_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b30eb770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to store metrics in a dictionary format for easy recall\n",
    "def metrics_to_dict(model_name, metrics, metrics_dict):\n",
    "    '''\n",
    "    Returns a dictionary with model name as key and dictionaries of metrics\n",
    "    as values\n",
    "    Nested dictionary has metric names as keys and the scores as values\n",
    "    \n",
    "    Takes the following arguments:\n",
    "    model_name: String of model name\n",
    "    metrics: list of metric scores from model.evaluate(), must match metric_names\n",
    "    metrics_dict: dictionary to be added to\n",
    "    '''\n",
    "    metrics_dict[model_name]={}\n",
    "    metric_names = ['loss', 'accuracy', 'precision']\n",
    "    for i,metric in enumerate(metric_names):\n",
    "        metrics_dict[model_name][metric] = metrics[i]\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ef36fa74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'simple_cnn': {'loss': 0.30743056535720825,\n",
       "  'accuracy': 0.8859060406684875,\n",
       "  'precision': 0.9215938448905945}}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dict = {}\n",
    "metrics_to_dict('simple_cnn', simple_cnn_val, metrics_dict)\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ea33d759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\n",
      "Yuhkai_notebook_scratch.ipynb\n",
      "data\n",
      "data.zip\n",
      "notebooks_scratch\n",
      "simple_cnn.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5857eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir saved_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "21494d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-p\n",
      "README.md\n",
      "Yuhkai_notebook_scratch.ipynb\n",
      "data\n",
      "data.zip\n",
      "notebooks_scratch\n",
      "saved_models\n",
      "simple_cnn.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6524e64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/simple_cnn\\assets\n"
     ]
    }
   ],
   "source": [
    "#saving off the model as pkl file\n",
    "#simple_cnn.save('saved_models/simple_cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d8eb97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading in pkl file\n",
    "from tensorflow.keras.models import load_model\n",
    "simple_cnn_loaded = load_model('saved_models/simple_cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23862e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 8ms/step - loss: 0.3074 - accuracy: 0.8859 - precision: 0.9216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30743056535720825, 0.8859060406684875, 0.9215938448905945]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing loaded pkl file\n",
    "simple_cnn_loaded.evaluate(val_images, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c5488a",
   "metadata": {},
   "source": [
    "## Second CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "27ae3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second convolutional neural network\n",
    "second_cnn = models.Sequential()\n",
    "\n",
    "#adding more convolutional and pooling layers\n",
    "second_cnn.add(layers.Conv2D(filters=64, kernel_size=(4,4), activation='relu', \n",
    "          input_shape=(64, 64, 1)))\n",
    "second_cnn.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "second_cnn.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "second_cnn.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "second_cnn.add(layers.Conv2D(filters=64, kernel_size=(4,4), activation='relu'))\n",
    "\n",
    "#two dense layers\n",
    "second_cnn.add(layers.Flatten())\n",
    "second_cnn.add(layers.Dense(64, activation='relu'))\n",
    "second_cnn.add(layers.Dense(64, activation='relu'))\n",
    "#output layer\n",
    "second_cnn.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4db487c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 61, 61, 64)        1088      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 11, 11, 64)        65600     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                495680    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 603,521\n",
      "Trainable params: 603,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "second_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "eab05290",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_cnn.compile(optimizer='sgd',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d43b2dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 5s 369ms/step - loss: 0.6819 - accuracy: 0.6463 - precision_2: 0.7470\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 4s 358ms/step - loss: 0.6455 - accuracy: 0.7429 - precision_2: 0.7429\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 4s 362ms/step - loss: 0.6090 - accuracy: 0.7429 - precision_2: 0.7429\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 4s 358ms/step - loss: 0.5814 - accuracy: 0.7429 - precision_2: 0.7429\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 4s 360ms/step - loss: 0.5713 - accuracy: 0.7429 - precision_2: 0.7429\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 4s 360ms/step - loss: 0.5689 - accuracy: 0.7429 - precision_2: 0.7429\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 4s 363ms/step - loss: 0.5679 - accuracy: 0.7429 - precision_2: 0.7429\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 4s 364ms/step - loss: 0.5669 - accuracy: 0.7429 - precision_2: 0.7429\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 4s 366ms/step - loss: 0.5660 - accuracy: 0.7429 - precision_2: 0.7429\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 4s 362ms/step - loss: 0.5652 - accuracy: 0.7429 - precision_2: 0.7429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e03cfe4fd0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_cnn.fit(train_images, train_labels, epochs=10, batch_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5528dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran ths second model multiple times, usually got stuck around 0.7429 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8e553c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_cnn.compile(optimizer='sgd',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "17c120a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 5s 361ms/step - loss: 0.4866 - accuracy: 0.7429 - precision_5: 0.7429\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 4s 362ms/step - loss: 0.4696 - accuracy: 0.7431 - precision_5: 0.7430\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 4s 357ms/step - loss: 0.4597 - accuracy: 0.7525 - precision_5: 0.7502\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 0.4367 - accuracy: 0.7695 - precision_5: 0.7641\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.4178 - accuracy: 0.8009 - precision_5: 0.7916\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.5014 - accuracy: 0.7985 - precision_5: 0.8149\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 4s 341ms/step - loss: 0.4388 - accuracy: 0.8090 - precision_5: 0.8135\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 4s 334ms/step - loss: 0.3947 - accuracy: 0.8284 - precision_5: 0.8229\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.4243 - accuracy: 0.8164 - precision_5: 0.8321\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 4s 365ms/step - loss: 0.4009 - accuracy: 0.8200 - precision_5: 0.8326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dfcd45c2e0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_cnn.fit(train_images, train_labels, epochs=10, batch_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8538c37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 2s 15ms/step - loss: 0.4306 - accuracy: 0.8497 - precision_5: 0.9647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4305930435657501, 0.8497483730316162, 0.9646749496459961]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_cnn_train = second_cnn.evaluate(train_images, train_labels)\n",
    "second_cnn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a6489cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 16ms/step - loss: 0.4541 - accuracy: 0.8150 - precision_5: 0.9491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45411476492881775, 0.8149568438529968, 0.9490740895271301]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_cnn_val = second_cnn.evaluate(val_images, val_labels)\n",
    "second_cnn_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48033f6",
   "metadata": {},
   "source": [
    "This second model has less accuracy (still overfit) but higher precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5ab1ef41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4173\n",
      "1043\n"
     ]
    }
   ],
   "source": [
    "print(len(train_images))\n",
    "print(len(val_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0730572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensor_lecture)",
   "language": "python",
   "name": "tensor_lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

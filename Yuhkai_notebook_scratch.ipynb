{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eb4b1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "\n",
    "import numpy as np\n",
    "import os, tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import image_dataset_from_directory \n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "import time\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from PIL import Image\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2464e9b2",
   "metadata": {},
   "source": [
    "## Image Load In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb3e2785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\n",
      "Yuhkai_notebook_scratch.ipynb\n",
      "data\n",
      "data.zip\n",
      "notebooks_scratch\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22933c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce2e6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\n",
      "Yuhkai_notebook_scratch.ipynb\n",
      "data\n",
      "data.zip\n",
      "notebooks_scratch\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d89e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\n",
      "Yuhkai_notebook_scratch.ipynb\n",
      "data\n",
      "data.zip\n",
      "notebooks_scratch\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a38bcfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the train data\n",
    "\n",
    "#starting from main project directory\n",
    "\n",
    "train_normal_dir = \"./data/chest_xray/train/NORMAL\"\n",
    "train_pneumonia_dir = \"./data/chest_xray/train/PNEUMONIA\"\n",
    "\n",
    "imgs_train_normal = [file for file in os.listdir(train_normal_dir) if file.endswith('.jpeg')]\n",
    "imgs_train_pneumonia = [file for file in os.listdir(train_pneumonia_dir) if file.endswith('.jpeg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aa8d7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normal_dir = \"./data/chest_xray/test/NORMAL\"\n",
    "test_pneumonia_dir = \"./data/chest_xray/test/PNEUMONIA\"\n",
    "\n",
    "imgs_test_normal = [file for file in os.listdir(test_normal_dir) if file.endswith('.jpeg')]\n",
    "imgs_test_pneumonia = [file for file in os.listdir(test_pneumonia_dir) if file.endswith('.jpeg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1cb7560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1341"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_train_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71fe4696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3875"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_train_pneumonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5935606e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IM-0115-0001.jpeg'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_train_normal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7777fb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'person1000_bacteria_2931.jpeg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_train_pneumonia[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af354b5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_test_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a574ee41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_test_pneumonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bc17eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5216, 624)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train = len(imgs_train_normal) + len(imgs_train_pneumonia)\n",
    "num_test = len(imgs_test_normal) + len(imgs_test_pneumonia)\n",
    "num_train, num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ed59797",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1f99e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4173 images belonging to 2 classes.\n",
      "Found 1043 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#rescale images to 64 by 64\n",
    "#create validation set as 20% of train set\n",
    "\n",
    "train_folder = \"./data/chest_xray/train\"\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "        train_folder, \n",
    "        target_size=(64, 64), \n",
    "        color_mode='grayscale', \n",
    "        class_mode='binary',\n",
    "        subset='training',\n",
    "        batch_size= num_train)\n",
    "\n",
    "validation_gen = train_datagen.flow_from_directory(\n",
    "        train_folder, \n",
    "        target_size=(64, 64), \n",
    "        color_mode='grayscale', \n",
    "        class_mode='binary',\n",
    "        subset='validation',\n",
    "        batch_size= num_train)\n",
    "\n",
    "test_folder = \"./data/chest_xray/test\"\n",
    "test_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, \n",
    "        target_size=(64, 64), color_mode='grayscale', \n",
    "        class_mode='binary', \n",
    "        batch_size= num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "279788e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_gen)\n",
    "val_images, val_labels = next(validation_gen)\n",
    "test_images, test_labels = next(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68728ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.34509805],\n",
       "        [0.35686275],\n",
       "        [0.41960788],\n",
       "        ...,\n",
       "        [0.3372549 ],\n",
       "        [0.29411766],\n",
       "        [0.3137255 ]],\n",
       "\n",
       "       [[0.38431376],\n",
       "        [0.3803922 ],\n",
       "        [0.38431376],\n",
       "        ...,\n",
       "        [0.34901962],\n",
       "        [0.32941177],\n",
       "        [0.31764707]],\n",
       "\n",
       "       [[0.35686275],\n",
       "        [0.43921572],\n",
       "        [0.41176474],\n",
       "        ...,\n",
       "        [0.44705886],\n",
       "        [0.5137255 ],\n",
       "        [0.49803925]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06e5a2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1dfef9f9be0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[0], cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "935ea49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.25882354],\n",
       "        [0.36078432],\n",
       "        [0.3803922 ],\n",
       "        ...,\n",
       "        [0.5568628 ],\n",
       "        [0.36862746],\n",
       "        [0.36078432]],\n",
       "\n",
       "       [[0.2627451 ],\n",
       "        [0.34509805],\n",
       "        [0.3921569 ],\n",
       "        ...,\n",
       "        [0.6       ],\n",
       "        [0.3647059 ],\n",
       "        [0.34509805]],\n",
       "\n",
       "       [[0.2392157 ],\n",
       "        [0.34117648],\n",
       "        [0.39607847],\n",
       "        ...,\n",
       "        [0.38823533],\n",
       "        [0.3803922 ],\n",
       "        [0.37254903]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.02352941],\n",
       "        [0.04705883],\n",
       "        [0.02352941],\n",
       "        ...,\n",
       "        [0.01568628],\n",
       "        [0.04313726],\n",
       "        [0.05490196]],\n",
       "\n",
       "       [[0.01960784],\n",
       "        [0.04313726],\n",
       "        [0.02745098],\n",
       "        ...,\n",
       "        [0.01960784],\n",
       "        [0.04313726],\n",
       "        [0.0627451 ]],\n",
       "\n",
       "       [[0.02352941],\n",
       "        [0.04705883],\n",
       "        [0.02352941],\n",
       "        ...,\n",
       "        [0.02352941],\n",
       "        [0.04313726],\n",
       "        [0.04313726]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dc80fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4173, 64, 64, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4e7a439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(image height, image width, color channels)\n",
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "094464c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9afb5b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4173,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a54af6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1043, 64, 64, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dab4d362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1043,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc6b5ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4173, 4096)\n",
      "(1043, 4096)\n",
      "(624, 4096)\n"
     ]
    }
   ],
   "source": [
    "#reshaping features for dense layers\n",
    "train_reshape = train_images.reshape(train_images.shape[0], -1)\n",
    "val_reshape = val_images.reshape(val_images.shape[0], -1)\n",
    "test_reshape = test_images.reshape(test_images.shape[0], -1)\n",
    "\n",
    "print(train_reshape.shape)\n",
    "print(val_reshape.shape)\n",
    "print(test_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fe78056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4173,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ad1fe23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1043,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "faa2ce7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92ed5628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4173, 1)\n",
      "(1043, 1)\n",
      "(624, 1)\n"
     ]
    }
   ],
   "source": [
    "#reshaping labels\n",
    "train_y = np.reshape(train_labels, (4173,1))\n",
    "val_y = np.reshape(val_labels, (1043,1))\n",
    "test_y = np.reshape(test_labels, (624,1))\n",
    "\n",
    "print(train_y.shape)\n",
    "print(val_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6717d227",
   "metadata": {},
   "source": [
    "# Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd619877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7430488974113135"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier()\n",
    "dummy_clf.fit(train_images, train_labels)\n",
    "dummy_clf.score(val_images, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3422e966",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1421aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c88c683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.add(layers.Dense(20, activation='relu', input_shape=(4096,)))\n",
    "baseline_model.add(layers.Dense(7, activation='relu'))\n",
    "baseline_model.add(layers.Dense(5, activation='relu'))\n",
    "baseline_model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f19cf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                81940     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 147       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 82,133\n",
      "Trainable params: 82,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ed41732",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.compile(optimizer='sgd', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "001757f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reshape[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9da999c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_reshape[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6067c9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "131/131 [==============================] - 4s 16ms/step - loss: 0.5611 - accuracy: 0.7388 - val_loss: 0.4850 - val_accuracy: 0.7430\n",
      "Epoch 2/50\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.3848 - accuracy: 0.8289 - val_loss: 0.3847 - val_accuracy: 0.8015\n",
      "Epoch 3/50\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2970 - accuracy: 0.8740 - val_loss: 0.5450 - val_accuracy: 0.7411\n",
      "Epoch 4/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2568 - accuracy: 0.8922 - val_loss: 0.2174 - val_accuracy: 0.9070\n",
      "Epoch 5/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2270 - accuracy: 0.9092 - val_loss: 0.4529 - val_accuracy: 0.8082\n",
      "Epoch 6/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1833 - accuracy: 0.9293 - val_loss: 0.3017 - val_accuracy: 0.8744\n",
      "Epoch 7/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1941 - accuracy: 0.9195 - val_loss: 0.1840 - val_accuracy: 0.9252\n",
      "Epoch 8/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1728 - accuracy: 0.9324 - val_loss: 0.2190 - val_accuracy: 0.9070\n",
      "Epoch 9/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1591 - accuracy: 0.9406 - val_loss: 0.4745 - val_accuracy: 0.8044\n",
      "Epoch 10/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1464 - accuracy: 0.9442 - val_loss: 0.1997 - val_accuracy: 0.9175\n",
      "Epoch 11/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1371 - accuracy: 0.9466 - val_loss: 0.5077 - val_accuracy: 0.7967\n",
      "Epoch 12/50\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.1407 - accuracy: 0.9458 - val_loss: 0.5697 - val_accuracy: 0.8150\n",
      "Epoch 13/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1507 - accuracy: 0.9394 - val_loss: 0.2964 - val_accuracy: 0.8792\n",
      "Epoch 14/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1325 - accuracy: 0.9494 - val_loss: 0.2455 - val_accuracy: 0.9070\n",
      "Epoch 15/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1256 - accuracy: 0.9526 - val_loss: 0.1472 - val_accuracy: 0.9434\n",
      "Epoch 16/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1272 - accuracy: 0.9514 - val_loss: 0.1438 - val_accuracy: 0.9444\n",
      "Epoch 17/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1186 - accuracy: 0.9540 - val_loss: 0.1840 - val_accuracy: 0.9262\n",
      "Epoch 18/50\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1360 - accuracy: 0.9461 - val_loss: 0.1430 - val_accuracy: 0.9463\n",
      "Epoch 19/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1186 - accuracy: 0.9545 - val_loss: 0.1734 - val_accuracy: 0.9319\n",
      "Epoch 20/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1216 - accuracy: 0.9545 - val_loss: 0.1553 - val_accuracy: 0.9396\n",
      "Epoch 21/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1071 - accuracy: 0.9593 - val_loss: 0.2306 - val_accuracy: 0.9118\n",
      "Epoch 22/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1102 - accuracy: 0.9557 - val_loss: 0.1406 - val_accuracy: 0.9473\n",
      "Epoch 23/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1206 - accuracy: 0.9561 - val_loss: 0.2257 - val_accuracy: 0.9108\n",
      "Epoch 24/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1111 - accuracy: 0.9569 - val_loss: 0.1391 - val_accuracy: 0.9453\n",
      "Epoch 25/50\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0994 - accuracy: 0.9636 - val_loss: 0.1442 - val_accuracy: 0.9453\n",
      "Epoch 26/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1069 - accuracy: 0.9612 - val_loss: 0.3903 - val_accuracy: 0.8562\n",
      "Epoch 27/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1117 - accuracy: 0.9588 - val_loss: 0.1536 - val_accuracy: 0.9434\n",
      "Epoch 28/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1042 - accuracy: 0.9624 - val_loss: 0.1791 - val_accuracy: 0.9300\n",
      "Epoch 29/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1217 - accuracy: 0.9547 - val_loss: 0.1516 - val_accuracy: 0.9415\n",
      "Epoch 30/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0991 - accuracy: 0.9617 - val_loss: 0.1576 - val_accuracy: 0.9396\n",
      "Epoch 31/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1049 - accuracy: 0.9607 - val_loss: 0.1372 - val_accuracy: 0.9463\n",
      "Epoch 32/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1044 - accuracy: 0.9602 - val_loss: 0.2065 - val_accuracy: 0.9195\n",
      "Epoch 33/50\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1029 - accuracy: 0.9619 - val_loss: 0.5356 - val_accuracy: 0.7996\n",
      "Epoch 34/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1082 - accuracy: 0.9609 - val_loss: 0.3702 - val_accuracy: 0.8686\n",
      "Epoch 35/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0967 - accuracy: 0.9645 - val_loss: 0.1414 - val_accuracy: 0.9453\n",
      "Epoch 36/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0974 - accuracy: 0.9648 - val_loss: 0.1651 - val_accuracy: 0.9367\n",
      "Epoch 37/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1008 - accuracy: 0.9602 - val_loss: 0.5427 - val_accuracy: 0.8063\n",
      "Epoch 38/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1004 - accuracy: 0.9626 - val_loss: 0.1610 - val_accuracy: 0.9396\n",
      "Epoch 39/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0933 - accuracy: 0.9669 - val_loss: 0.1526 - val_accuracy: 0.9406\n",
      "Epoch 40/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0978 - accuracy: 0.9621 - val_loss: 0.4005 - val_accuracy: 0.8571\n",
      "Epoch 41/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0950 - accuracy: 0.9641 - val_loss: 0.3299 - val_accuracy: 0.8840\n",
      "Epoch 42/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0970 - accuracy: 0.9648 - val_loss: 0.3614 - val_accuracy: 0.8734\n",
      "Epoch 43/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0886 - accuracy: 0.9691 - val_loss: 0.1739 - val_accuracy: 0.9348\n",
      "Epoch 44/50\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9633 - val_loss: 0.1686 - val_accuracy: 0.9358\n",
      "Epoch 45/50\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0888 - accuracy: 0.9662 - val_loss: 0.1551 - val_accuracy: 0.9463\n",
      "Epoch 46/50\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0858 - accuracy: 0.9674 - val_loss: 0.1462 - val_accuracy: 0.9434\n",
      "Epoch 47/50\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0879 - accuracy: 0.9676 - val_loss: 0.1490 - val_accuracy: 0.9453\n",
      "Epoch 48/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0973 - accuracy: 0.9631 - val_loss: 0.1476 - val_accuracy: 0.9434\n",
      "Epoch 49/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0803 - accuracy: 0.9703 - val_loss: 0.2091 - val_accuracy: 0.9281\n",
      "Epoch 50/50\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0834 - accuracy: 0.9696 - val_loss: 0.2825 - val_accuracy: 0.9003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dfe661ffa0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model.fit(train_reshape, \n",
    "                   train_y, \n",
    "                   epochs=50, \n",
    "                   batch_size=32, \n",
    "                   validation_data=(val_reshape, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f9baa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 1s 7ms/step - loss: 0.2145 - accuracy: 0.9183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21445898711681366, 0.9182842373847961]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train = baseline_model.evaluate(train_reshape, train_y)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d260b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2825 - accuracy: 0.9003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2825089991092682, 0.9002876281738281]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_val = baseline_model.evaluate(val_reshape, val_y)\n",
    "results_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bb455a",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks - CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c34d54c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up a simple convolutional model\n",
    "simple_cnn = models.Sequential()\n",
    "\n",
    "simple_cnn.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', \n",
    "          input_shape=(64, 64, 1)))\n",
    "simple_cnn.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "simple_cnn.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "#single dense layer\n",
    "simple_cnn.add(layers.Flatten())\n",
    "simple_cnn.add(layers.Dense(64, activation='relu'))\n",
    "#output layer\n",
    "simple_cnn.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f6449c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 62, 62, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 29, 29, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 53824)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                3444800   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,482,433\n",
      "Trainable params: 3,482,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bf0c7664",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn.compile(optimizer='sgd',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5e288fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 9s 594ms/step - loss: 0.4193 - accuracy: 0.7992 - precision: 0.7888\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 7s 602ms/step - loss: 0.4524 - accuracy: 0.8243 - precision: 0.8270\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 7s 598ms/step - loss: 0.3948 - accuracy: 0.8351 - precision: 0.8324\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 7s 643ms/step - loss: 0.4293 - accuracy: 0.8112 - precision: 0.8284\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 7s 602ms/step - loss: 0.3908 - accuracy: 0.8430 - precision: 0.8557\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 6s 587ms/step - loss: 0.4066 - accuracy: 0.8203 - precision: 0.8422\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 7s 622ms/step - loss: 0.3139 - accuracy: 0.8890 - precision: 0.8861\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 7s 612ms/step - loss: 0.3312 - accuracy: 0.8658 - precision: 0.8812\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 7s 598ms/step - loss: 0.4278 - accuracy: 0.8387 - precision: 0.8539\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 7s 610ms/step - loss: 0.2801 - accuracy: 0.9001 - precision: 0.8999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dfcd45c730>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn.fit(train_images, train_labels, epochs=10, batch_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6e3af26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 4s 22ms/step - loss: 0.2789 - accuracy: 0.9154 - precision: 0.9467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2788931131362915, 0.9154085516929626, 0.9466666579246521]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn_train = simple_cnn.evaluate(train_images, train_labels)\n",
    "simple_cnn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "41a4c57e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 25ms/step - loss: 0.3074 - accuracy: 0.8859 - precision: 0.9216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30743056535720825, 0.8859060406684875, 0.9215938448905945]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn_val = simple_cnn.evaluate(val_images, val_labels)\n",
    "simple_cnn_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee00b1",
   "metadata": {},
   "source": [
    "Our first CNN had some overfitting (91% accuracy on the train set and 89% accuracy on the validation set). Precision was also better for the train set (94%) than the validation set (92%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c0260709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(simple_cnn_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b30eb770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to store metrics in a dictionary format for easy recall\n",
    "def metrics_to_dict(model_name, metrics, metrics_dict):\n",
    "    '''\n",
    "    Returns a dictionary with model name as key and dictionaries of metrics\n",
    "    as values\n",
    "    Nested dictionary has metric names as keys and the scores as values\n",
    "    \n",
    "    Takes the following arguments:\n",
    "    model_name: String of model name\n",
    "    metrics: list of metric scores from model.evaluate(), must match metric_names\n",
    "    metrics_dict: dictionary to be added to\n",
    "    '''\n",
    "    metrics_dict[model_name]={}\n",
    "    metric_names = ['loss', 'accuracy', 'precision']\n",
    "    for i,metric in enumerate(metric_names):\n",
    "        metrics_dict[model_name][metric] = metrics[i]\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ef36fa74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'simple_cnn': {'loss': 0.30743056535720825,\n",
       "  'accuracy': 0.8859060406684875,\n",
       "  'precision': 0.9215938448905945}}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dict = {}\n",
    "metrics_to_dict('simple_cnn', simple_cnn_val, metrics_dict)\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ea33d759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\n",
      "Yuhkai_notebook_scratch.ipynb\n",
      "data\n",
      "data.zip\n",
      "notebooks_scratch\n",
      "simple_cnn.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5857eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir saved_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "21494d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-p\n",
      "README.md\n",
      "Yuhkai_notebook_scratch.ipynb\n",
      "data\n",
      "data.zip\n",
      "notebooks_scratch\n",
      "saved_models\n",
      "simple_cnn.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6524e64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/simple_cnn\\assets\n"
     ]
    }
   ],
   "source": [
    "#saving off the model as pkl file\n",
    "#simple_cnn.save('saved_models/simple_cnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c5488a",
   "metadata": {},
   "source": [
    "## Second CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "27ae3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second convolutional neural network\n",
    "second_cnn = models.Sequential()\n",
    "\n",
    "#adding more convolutional and pooling layers\n",
    "second_cnn.add(layers.Conv2D(filters=64, kernel_size=(4,4), activation='relu', \n",
    "          input_shape=(64, 64, 1)))\n",
    "second_cnn.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "second_cnn.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "second_cnn.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "second_cnn.add(layers.Conv2D(filters=64, kernel_size=(4,4), activation='relu'))\n",
    "\n",
    "#two dense layers\n",
    "second_cnn.add(layers.Flatten())\n",
    "second_cnn.add(layers.Dense(64, activation='relu'))\n",
    "second_cnn.add(layers.Dense(64, activation='relu'))\n",
    "#output layer\n",
    "second_cnn.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4db487c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 61, 61, 64)        1088      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 11, 11, 64)        65600     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                495680    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 603,521\n",
      "Trainable params: 603,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "second_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "eab05290",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_cnn.compile(optimizer='sgd',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d43b2dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 5s 369ms/step - loss: 0.6819 - accuracy: 0.6463 - precision_2: 0.7470\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 4s 358ms/step - loss: 0.6455 - accuracy: 0.7429 - precision_2: 0.7429\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 4s 362ms/step - loss: 0.6090 - accuracy: 0.7429 - precision_2: 0.7429\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 4s 358ms/step - loss: 0.5814 - accuracy: 0.7429 - precision_2: 0.7429\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 4s 360ms/step - loss: 0.5713 - accuracy: 0.7429 - precision_2: 0.7429\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 4s 360ms/step - loss: 0.5689 - accuracy: 0.7429 - precision_2: 0.7429\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 4s 363ms/step - loss: 0.5679 - accuracy: 0.7429 - precision_2: 0.7429\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 4s 364ms/step - loss: 0.5669 - accuracy: 0.7429 - precision_2: 0.7429\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 4s 366ms/step - loss: 0.5660 - accuracy: 0.7429 - precision_2: 0.7429\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 4s 362ms/step - loss: 0.5652 - accuracy: 0.7429 - precision_2: 0.7429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e03cfe4fd0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_cnn.fit(train_images, train_labels, epochs=10, batch_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5528dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran ths second model multiple times, usually got stuck around 0.7429 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8e553c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_cnn.compile(optimizer='sgd',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "17c120a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 5s 361ms/step - loss: 0.4866 - accuracy: 0.7429 - precision_5: 0.7429\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 4s 362ms/step - loss: 0.4696 - accuracy: 0.7431 - precision_5: 0.7430\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 4s 357ms/step - loss: 0.4597 - accuracy: 0.7525 - precision_5: 0.7502\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 0.4367 - accuracy: 0.7695 - precision_5: 0.7641\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.4178 - accuracy: 0.8009 - precision_5: 0.7916\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.5014 - accuracy: 0.7985 - precision_5: 0.8149\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 4s 341ms/step - loss: 0.4388 - accuracy: 0.8090 - precision_5: 0.8135\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 4s 334ms/step - loss: 0.3947 - accuracy: 0.8284 - precision_5: 0.8229\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.4243 - accuracy: 0.8164 - precision_5: 0.8321\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 4s 365ms/step - loss: 0.4009 - accuracy: 0.8200 - precision_5: 0.8326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dfcd45c2e0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_cnn.fit(train_images, train_labels, epochs=10, batch_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8538c37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 2s 15ms/step - loss: 0.4306 - accuracy: 0.8497 - precision_5: 0.9647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4305930435657501, 0.8497483730316162, 0.9646749496459961]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_cnn_train = second_cnn.evaluate(train_images, train_labels)\n",
    "second_cnn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a6489cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 16ms/step - loss: 0.4541 - accuracy: 0.8150 - precision_5: 0.9491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45411476492881775, 0.8149568438529968, 0.9490740895271301]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_cnn_val = second_cnn.evaluate(val_images, val_labels)\n",
    "second_cnn_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48033f6",
   "metadata": {},
   "source": [
    "This second model has less accuracy (still overfit) but higher precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5ab1ef41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4173\n",
      "1043\n"
     ]
    }
   ],
   "source": [
    "print(len(train_images))\n",
    "print(len(val_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0730572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensor_lecture)",
   "language": "python",
   "name": "tensor_lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
